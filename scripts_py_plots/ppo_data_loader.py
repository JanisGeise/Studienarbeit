"""
    brief:
        - script responsible for handling all the loading, sorting and merging of the data created when running the
          PPO-training for different cases

    dependencies:
        - None

    prerequisites:
        - None
"""
import pickle
import torch as pt

from glob import glob
from natsort import natsorted


def load_trajectory_data(path: str) -> dict:
    """
    load observations_*.pkl files containing all the data generated during training and sort them into a dict

    :param path: path to directory containing the files
    :return: dict with actions, states, cl, cd. Each parameter contains one tensor with the length of N_episodes, each
             entry has all the trajectories sampled in this episode (cols = N_trajectories, rows = length_trajectories)
    """
    # sort imported data wrt to episode number
    files = natsorted(glob(path + "observations_*.pkl"))
    observations = [pickle.load(open(file, "rb")) for file in files]
    traj_length = len(observations[0][0]["actions"])

    data = {"n_workers": len(observations[0])}

    # sort the trajectories from all workers wrt the episode
    shape, counter, mb_episodes, mb_file_list = (traj_length, data["n_workers"]), 0, 0, []
    actions, cl, cd, rewards, alpha, beta = pt.zeros(shape), pt.zeros(shape), pt.zeros(shape), pt.zeros(shape),\
                                            pt.zeros(shape), pt.zeros(shape)
    states = pt.zeros((shape[0], observations[0][0]["states"].size()[1], shape[1]))
    shape = (len(observations), traj_length, data["n_workers"])
    data["actions"], data["cl"], data["cd"], = pt.zeros(shape), pt.zeros(shape), pt.zeros(shape)
    data["rewards"], data["alpha"], data["beta"], = pt.zeros(shape), pt.zeros(shape), pt.zeros(shape)
    data["states"] = pt.zeros((shape[0], shape[1], observations[0][0]["states"].size()[1], shape[2]))
    for episode in range(len(observations)):
        for worker in range(len(observations[episode])):
            # in case a trajectory has no values in it, drlfoam returns emtpy dict
            if not bool(observations[episode][worker]):
                counter += 1
                continue
            # omit failed trajectories in case the trajectory only converged partly
            elif observations[episode][worker]["actions"].size()[0] < traj_length:
                counter += 1
                continue
            else:
                actions[:, worker] = observations[episode][worker]["actions"]
                states[:, :, worker] = observations[episode][worker]["states"]
                cl[:, worker] = observations[episode][worker]["cl"]
                cd[:, worker] = observations[episode][worker]["cd"]
                rewards[:, worker] = observations[episode][worker]["rewards"]
                alpha[:, worker] = observations[episode][worker]["alpha"]
                beta[:, worker] = observations[episode][worker]["beta"]

        # check if trajectories are generated by CFD or by env. models -> if there exist a tag then count this episode
        if "generated_by" in observations[episode][0]:
            if observations[episode][0]["generated_by"] == "env_models":
                mb_episodes += 1
                mb_file_list.append(f"{episode}.pkl")

        data["actions"][episode, :, :] = actions
        data["states"][episode, :, :] = states
        data["cl"][episode, :, :] = cl
        data["cd"][episode, :, :] = cd
        data["rewards"][episode, :, :] = rewards
        data["alpha"][episode, :, :] = alpha
        data["beta"][episode, :, :] = beta

    # check how many trajectories failed
    if counter > 0:
        print(f"found {counter} failed trajectories")
    else:
        print("found no invalid trajectories")

    # load value-, policy and MSE losses of PPO training if the training didn't crash
    if len(glob(path + "training_history.pkl")) > 0:
        data["network_data"] = pickle.load(open(path + "training_history.pkl", "rb"))

    # add ratio (MB / MF) episodes = MB_episodes / (all_episodes - MB_episodes)
    data["MB_MF"] = mb_episodes / (len(observations) - mb_episodes)

    # import and sort training- and validation losses of the environment models, if MB-DRL was used still TO_DO
    if len(glob(path + "env_model_loss_*.pkl")) > 0:
        files = natsorted(glob(path + "env_model_loss_*.pkl"))
        losses = [pickle.load(open(file, "rb")) for file in files]
        loss = {"here_sorting_of_losses": losses}
        data.update(loss)

    return data


def load_all_data(settings: dict) -> list[dict]:
    """
    wrapper function for loading the results of the PPO-training and sorting it wrt episodes

    :param settings: setup containing all paths etc.
    :return: a list containing a dictionary with all the data from each case
    """
    # load the results of the training
    loaded_data = []

    if settings["avg_over_cases"]:
        for c in range(len(settings["case_name"])):
            case_data = []

            # assuming each case directory contains subdirectories with training data ran with different seeds,
            # exclude directories named "plots", readme files, logs etc.
            dirs = [d for d in glob("".join([settings["main_load_path"], settings["path_controlled"],
                                             settings["case_name"][c], "/seed[0-9]"]))]

            for d in dirs:
                case_data.append(load_trajectory_data(d + "/"))

            # merge training results from same case, but different seeds episode-wise
            loaded_data.append(merge_results_for_diff_seeds(case_data, n_seeds=len(case_data)))

    else:
        for c in range(len(settings["case_name"])):
            loaded_data.append(load_trajectory_data(settings["main_load_path"] + settings["path_controlled"] +
                                                    settings["case_name"][c]))
    return loaded_data


def average_results_for_each_case(data: list) -> dict:
    """
    average the loaded results of the training periode wrt the episode for each imported case

    :param data: list containing a dict for each imported case containing all the results of the training
    :return: dict containing the mean actions, cl, cd, alpha, beta and rewards as well as the corresponding standard
             deviation wrt the episode
    """
    # calculate the mean and std. deviation in each episode for each case
    avg_data = {"mean_cl": [], "std_cl": [], "mean_cd": [], "std_cd": [], "mean_actions": [], "std_actions": [],
                "mean_rewards": [], "std_rewards": [], "mean_alpha": [], "std_alpha": [], "mean_beta": [],
                "std_beta": [], "tot_mean_rewards": [], "tot_std_rewards": [], "tot_mean_cd": [], "tot_std_cd": [],
                "tot_mean_cl": [], "tot_std_cl": [], "var_beta_fct": [], "buffer_size": [], "len_traj": [],
                "ratio_MB_MF": []}
    names, keys = {}, ["cl", "cd", "actions", "rewards", "alpha", "beta"]

    for case in range(len(data)):
        n_episodes, len_trajectory = data[case]["actions"].size()[0], data[case]["actions"].size()[1]

        for key in keys:
            # reshape data and compute mean wrt to episode
            names[key] = data[case][key].reshape((n_episodes, len_trajectory * data[case]["n_workers"]))
            avg_data[f"mean_" + key].append(pt.mean(names[key], dim=1))
            avg_data[f"std_" + key].append(pt.std(names[key], dim=1))

            # total mean of rewards, cl and cd of complete training for each case
            if key != "alpha" and key != "beta" and key != "actions":
                avg_data[f"tot_mean_" + key].append(pt.mean(data[case][key]))
                avg_data[f"tot_std_" + key].append(pt.std(data[case][key]))

        # compute variance of the (mean) beta-distribution of each episode
        # var = (alpha*beta) / ((alpha + beta)^2 * (alpha+beta+1))
        var = (avg_data["mean_alpha"][case] * avg_data["mean_beta"][case]) / \
              ((avg_data["mean_alpha"][case] + avg_data["mean_beta"][case]) ** 2 *
               (avg_data["mean_alpha"][case] + avg_data["mean_beta"][case] + 1))
        avg_data["var_beta_fct"].append(var)

        # info about the setup, assuming constant sample rate of 100 Hz
        if "n_seeds" in data[case]:
            avg_data["buffer_size"].append(int(data[case]["n_workers"] / data[case]["n_seeds"]))

        else:
            avg_data["buffer_size"].append(data[case]["n_workers"])
        avg_data["len_traj"].append(int(len_trajectory / 100))

        if "generated_by" in data[case]:
            avg_data["ratio_MB_MF"].append(data[case]["MB_MF"])

        # still TO_DO
        if "train_loss_cd" in data[case]:
            keys = ["train_loss_cl_p", "val_loss_cl_p", "train_loss_cd", "val_loss_cd"]
            for key in keys:
                avg_data[f"mean_" + key].append(pt.mean(data[case][key], dim=0))
                avg_data[f"std_" + key].append(pt.std(data[case][key], dim=0))

    return avg_data


def merge_results_for_diff_seeds(data: list, n_seeds: int) -> dict:
    """
    merge the trajectories of the PPO-trainings for different seeds episode-wise

    prerequisites: all trainings are done with the same setup (same number of workers etc. but e.g. trainings
    initialized with different seeds)

    :param data: the loaded training data from all cases which should be merged
    :param n_seeds: number of cases
    :return: a dictionary containing the merged data
    """
    n_traj = sum([data[seed]["n_workers"] for seed in range(n_seeds)])
    shape = (data[0]["cd"].size(0), data[0]["cd"].size(1), n_traj)
    states = pt.zeros((data[0]["states"].size(0), data[0]["states"].size(1), data[0]["states"].size(2), n_traj))

    merged_data = {"n_workers": n_traj, "network_data": [data[seed]["network_data"] for seed in range(len(data))],
                   "n_seeds": n_seeds, "cl": pt.zeros(shape), "cd": pt.zeros(shape), "actions": pt.zeros(shape),
                   "rewards": pt.zeros(shape), "alpha": pt.zeros(shape), "beta": pt.zeros(shape)}
    keys = ["cl", "cd", "actions", "rewards", "alpha", "beta"]

    for seed in range(n_seeds):
        for k in keys:
            merged_data[k][:, :, data[seed]["n_workers"] * seed:data[seed]["n_workers"] * (seed + 1)] = data[seed][k]
        states[:, :, :, data[seed]["n_workers"] * seed:data[seed]["n_workers"] * (seed + 1)] = data[seed]["states"]

    # sort the states into dict
    merged_data["states"] = states

    return merged_data


if __name__ == "__main__":
    pass
